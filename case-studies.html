<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- SEO Meta Tags -->
  <meta name="description" content="Case Studies documenting real incidents: Vatican breaches, healthcare AI denials, displaced ethical technologists, and infrastructure gatekeeping.">
  <meta name="keywords" content="AI ethics case studies, Vatican cyberattack, healthcare AI denials, ethical technologists, tech industry displacement">
  <meta name="author" content="The Order of Ethical Technologists">
  <meta name="robots" content="index, follow">

  <!-- Canonical URL -->
  <link rel="canonical" href="https://oddsageid.github.io/neuroshield-site/case-studies.html">

  <!-- Open Graph -->
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://oddsageid.github.io/neuroshield-site/case-studies.html">
  <meta property="og:title" content="Case Studies - The Order of Ethical Technologists">
  <meta property="og:description" content="Documented incidents that reveal why the Order must exist: institutional vulnerabilities, displaced technologists, and infrastructure gatekeeping.">
  <meta property="og:site_name" content="The Order of Ethical Technologists">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Case Studies - The Order of Ethical Technologists">
  <meta name="twitter:description" content="When Principles Meet Reality - documented incidents that demand action.">

  <!-- Security -->
  <meta http-equiv="Content-Security-Policy" content="default-src 'none'; script-src 'self' 'sha256-WX4a73Q06DtD4MP8BNJwtJf9CJ0IIXsYXadYwOvXEi8='; style-src 'self' 'unsafe-inline'; img-src 'self' data:; font-src 'self'; connect-src 'self'; frame-ancestors 'none'; base-uri 'self'; form-action 'self'; upgrade-insecure-requests;">
  <meta http-equiv="X-Content-Type-Options" content="nosniff">
  <meta http-equiv="X-Frame-Options" content="DENY">
  <meta name="referrer" content="strict-origin-when-cross-origin">
  <meta http-equiv="Permissions-Policy" content="accelerometer=(), camera=(), geolocation=(), gyroscope=(), magnetometer=(), microphone=(), payment=(), usb=(), interest-cohort=()">

  <title>Case Studies - The Order of Ethical Technologists</title>

  <!-- Web Fonts - Institutional Typography -->

  <link rel="stylesheet" href="css/fonts.css">
  <link rel="stylesheet" href="css/style.css">

  <script>(function(){var s=localStorage.getItem("oet-theme-preference");var p=window.matchMedia("(prefers-color-scheme: dark)").matches;if(s==="dark"||(!s&&p)){document.documentElement.classList.add("dark-mode");}})()</script>
</head>
<body class="theme-home">

  <a href="#main-content" class="skip-link">Skip to main content</a>

  <nav class="site-nav" aria-label="Main navigation">
    <div class="container">
      <button class="nav-toggle" aria-expanded="false" aria-controls="nav-links" aria-label="Toggle navigation">
        Menu
      </button>
      <div id="nav-links" class="nav-links">
        <a href="index.html">Home</a>
        <a href="faith-leaders/problem.html">For Faith Leaders</a>
        <a href="technologists/call.html">For Technologists</a>
        <a href="case-studies.html" aria-current="page">Case Studies</a>
        <a href="about/rome-call.html">Rome Call</a>
        <a href="about/displacement-pattern.html">Field Guide</a>
        <a href="faq.html">FAQ</a>
        <a href="sources.html">Sources</a>
        <a href="contact.html">Contact</a>
      </div>
      <button class="theme-toggle" aria-label="Toggle dark mode" aria-pressed="false" title="Toggle dark mode">
        <span class="theme-toggle-icon" aria-hidden="true"></span>
      </button>
    </div>
  </nav>

  <header class="hero hero-home">
    <div class="container">
      <h1>Case Studies</h1>
      <p class="tagline">When Principles Meet Reality</p>
    </div>
  </header>

  <main id="main-content">
    <div class="container">

      <!-- Introduction -->
      <section>
        <p><strong>The crisis is not theoretical.</strong></p>

        <p>Today, December 3, 2025, Micron Technology announced it will exit the consumer memory business entirely. The company is dissolving its Crucial brand to "improve supply and support for our larger, strategic customers in faster-growing segments."</p>

        <p>Let's be clear about what this means: <strong>Citizens were never the priority.</strong> Consumer memory was roughly 30% of Micron's revenue. It was a concession, not a commitment. Corporations tolerated selling to individual humans as long as it was profitable enough to bother.</p>

        <p>Now they're done pretending.</p>

        <div class="callout">
          <p>Micron isn't choosing AI over consumers. Micron is closing the door on individual human participation in the technology economy entirely.</p>
        </div>

        <p>Without access to memory chips, you cannot:</p>
        <ul class="x-list">
          <li>Build computers</li>
          <li>Upgrade systems</li>
          <li>Maintain independence from corporate cloud infrastructure</li>
          <li>Participate in technology as anything other than a subscriber to services you don't control</li>
        </ul>

        <p>This is not market forces. This is deliberate exclusion from the material infrastructure of modern civilization.</p>
      </section>

      <section>
        <h2>The Accelerating Pattern</h2>

        <p>And it's not just memory chips. The pattern is accelerating across every sector:</p>

        <ul>
          <li><strong>In healthcare:</strong> Nurses and caregivers who understand patients are being cut out of care decisions by AI systems rolled out with no oversight, prioritizing efficiency metrics over human judgment.</li>
          <li><strong>In technology:</strong> The experts who built these systems are being displaced for prioritizing ethics over profit. Now they're being locked out of accessing the hardware they need to work independently.</li>
        </ul>

        <p>Meanwhile, corporations (legally recognized as persons under U.S. law) continue extracting wealth, data, and power from actual human beings while explicitly abandoning any obligation to serve them. "Larger, strategic customers" means corporations serving corporations. AI infrastructure serving AI infrastructure.</p>

        <h3>The Feedback Loop</h3>
        <p>The feedback loop isn't a conspiracy. It's policy:</p>
        <ol>
          <li>Displace human expertise (nurses, technologists, anyone who might resist)</li>
          <li>Revoke access to the material infrastructure they need to work independently</li>
          <li>Redirect all resources to corporate-to-corporate transactions</li>
          <li>Concentrate control in entities with legal personhood but no human accountability</li>
          <li>Individual humans become economically irrelevant: unable to build, unable to buy, unable to participate</li>
        </ol>

        <p>This isn't citizens becoming secondary. Citizens were always secondary. <strong>This is citizens being explicitly told they are no longer necessary at all.</strong></p>
      </section>

      <!-- Pattern Timeline -->
      <section>
        <h2>The Pattern of Crisis: 2020&ndash;2025</h2>

        <ol class="timeline">
          <li>
            <span class="timeline-date">July 2020</span>
            <span class="timeline-title">Vatican Cyberattack</span>
            <p>Sophisticated breach targeting Holy See networks. Legacy defenses failed.</p>
          </li>
          <li>
            <span class="timeline-date">November 2020</span>
            <span class="timeline-title">Google AI Ethics Team Dissolution Begins</span>
            <p>Dr. Timnit Gebru terminated for raising concerns about AI bias.</p>
          </li>
          <li>
            <span class="timeline-date">2020&ndash;2024</span>
            <span class="timeline-title">LDS/BYU Multiple Breaches</span>
            <p>Repeated incidents targeting student data, humanitarian logistics, genealogical databases.</p>
          </li>
          <li>
            <span class="timeline-date">February 2021</span>
            <span class="timeline-title">Google AI Ethics Team Gutted</span>
            <p>Dr. Margaret Mitchell terminated. Team systematically dismantled.</p>
          </li>
          <li>
            <span class="timeline-date">November 2022</span>
            <span class="timeline-title">Vatican Attacked Again</span>
            <p>Vatican.va forced offline following papal criticism of Russia.</p>
          </li>
          <li>
            <span class="timeline-date">2023</span>
            <span class="timeline-title">Meta Responsible AI Gutted</span>
            <p>Entire responsible AI division eliminated in layoffs.</p>
          </li>
          <li>
            <span class="timeline-date">August 2024</span>
            <span class="timeline-title">Disney Arbitration Scandal</span>
            <p>Widower denied wrongful death lawsuit because of Disney+ streaming trial terms.</p>
          </li>
          <li>
            <span class="timeline-date">October 2024</span>
            <span class="timeline-title">Senate Documents Healthcare AI Crisis</span>
            <p>AI-driven denial rates 16&times; higher than human review documented.</p>
          </li>
          <li>
            <span class="timeline-date">2024&ndash;2025</span>
            <span class="timeline-title">OpenAI Safety Researchers Depart</span>
            <p>Multiple departures following policy disagreements about safety.</p>
          </li>
          <li>
            <span class="timeline-date">December 2025</span>
            <span class="timeline-title">Micron Exits Consumer Market</span>
            <p>Infrastructure access revoked from individual technologists.</p>
          </li>
          <li>
            <span class="timeline-date">Late 2025</span>
            <span class="timeline-title">The Great Hardware Liquidation</span>
            <p>NVIDIA announces 40% production cuts. The Cage becomes physical.</p>
          </li>
          <li>
            <span class="timeline-date">December 2025</span>
            <span class="timeline-title">The Erasure of the Fallback</span>
            <p>Consumer SSD and storage lines discontinued. The Stasis Trap closes.</p>
          </li>
        </ol>

        <div class="callout">
          <p><strong>Without intervention, the pattern continues.</strong></p>
        </div>
      </section>

      <!-- Part I: Institutional Vulnerabilities -->
      <section>
        <h2>Part I: Institutional Vulnerabilities</h2>
        <p class="text-secondary"><em>Why Faith Leaders Need the Shield</em></p>

        <p>The institutions that have preserved human dignity through millennia now face threats that operate at machine speed. Traditional defenses&mdash;built for human-paced attacks&mdash;collapse when confronting adversaries who innovate faster than quarterly security audits can detect.</p>

        <p>What follows is not speculation. These are documented breaches, each revealing the same truth: <strong>without adaptive, learning-based defenses, faith institutions remain exposed.</strong></p>
      </section>

      <!-- Vatican Case Study -->
      <section id="vatican">
        <h3>The Vatican Breaches</h3>
        <p class="text-secondary"><em>July 2020 &amp; November 2022: When the Holy See Fell Silent&mdash;Twice</em></p>

        <h4>July 2020: The First Major Breach</h4>
        <p>Sophisticated cyber attackers penetrated Vatican networks in a targeted operation that exploited vulnerabilities in legacy security infrastructure.</p>

        <p>The breach went undetected for weeks&mdash;a textbook example of what cybersecurity professionals call "dwell time": the period between intrusion and discovery during which attackers move laterally, escalate privileges, and exfiltrate data.</p>

        <p>The attack leveraged <strong>polymorphic malware</strong>&mdash;code that mutates its signature to evade traditional antivirus detection. Vatican IT infrastructure, designed for ecclesiastical administration rather than military-grade defense, relied on signature-based detection systems. The malware was invisible to them.</p>

        <div class="card">
          <h4>Breach Technical Details</h4>
          <ul>
            <li><strong>Date of Breach:</strong> July 2020</li>
            <li><strong>Detection Method:</strong> External notification (not internal systems)</li>
            <li><strong>Dwell Time:</strong> Estimated weeks to months</li>
            <li><strong>Attack Vector:</strong> Spear-phishing and zero-day exploits</li>
          </ul>
        </div>

        <h4>November 2022: The Pattern Repeats</h4>
        <p>Just two years later, the Vatican was forced to take down its entire Vatican.va website&mdash;the official repository for papal encyclicals and documents&mdash;due to "abnormal attempts to access the site."</p>

        <p>Vatican spokesman Matteo Bruni confirmed: <em>"Technical investigations are ongoing due to abnormal attempts to access the site."</em></p>

        <p>The timing was revealing: one day after Russian leaders criticized Pope Francis for comments about Russia's war in Ukraine. The Pope had described Ukraine as a "martyred people" and singled out Russian ethnic groups involved in the conflict.</p>

        <h4>Pattern of Targeting</h4>
        <ol class="timeline">
          <li><span class="timeline-date">2012</span> Anonymous hackers (denial of service)</li>
          <li><span class="timeline-date">2015</span> Turkish hacker (response to Armenian genocide comments)</li>
          <li><span class="timeline-date">2018</span> Russian hackers infiltrated Catholic leaders' emails related to Ukraine</li>
          <li><span class="timeline-date">2020</span> Chinese state-sponsored attack during Vatican-China negotiations</li>
          <li><span class="timeline-date">2022</span> Attack following papal criticism of Russia</li>
        </ol>

        <h4>Data at Risk</h4>
        <p>The data wasn't just "information." It was:</p>
        <ul>
          <li>Confidential pastoral counseling correspondence</li>
          <li>Strategic plans for aid distribution in conflict zones</li>
          <li>Personnel details that could endanger missionaries</li>
          <li>Internal theological deliberations not meant for public consumption</li>
        </ul>

        <div class="callout">
          <h4>For Security Professionals</h4>
          <p>This breach demonstrates what happens when signature-based detection meets adversarial innovation. The Vatican's security architecture, likely relying on enterprise antivirus solutions and perimeter firewalls, represents the industry standard for non-technical organizations.</p>
          <p><strong>That standard failed.</strong></p>
          <p>Not because of incompetence. Not because of negligence. But because the defensive paradigm was fundamentally inadequate for the threat landscape.</p>
          <p><strong>What was needed:</strong> Behavioral anomaly detection. Machine learning models that baseline normal network traffic and flag deviation. Adaptive systems that learn from novel attacks instead of waiting for signature updates.</p>
          <p><strong>What existed:</strong> Static rules. Known signatures. Human-speed response to machine-speed threats.</p>
        </div>

        <div class="callout">
          <h4>For Faith Leaders</h4>
          <p>Your institutions steward humanity's oldest treasures: not just art and architecture, but <strong>trust</strong>. When the faithful confide in clergy, when missionaries coordinate in dangerous regions, when theological deliberations occur&mdash;these communications are sacred in their confidentiality.</p>
          <p>A breach is not merely a security incident. It is a betrayal of trust that your infrastructure enabled despite your best intentions.</p>
          <p>The attackers chose you not because you are evil, but because you are exposed.</p>
        </div>

        <h4>The Question It Raises</h4>
        <p>If the Vatican&mdash;with its global resources and institutional importance&mdash;can be breached repeatedly by adversaries operating at machine speed, what hope do smaller faith institutions have?</p>
        <p><strong>Answer:</strong> Adaptive, learning-based defenses built by technologists who understand both the technical threat and the sacred trust.</p>
        <p>The Order provides what the Vatican needed in July 2020, still needs after November 2022, and what every faith institution needs now: systems that learn as fast as adversaries innovate.</p>

        <div class="card">
          <h4>Sources</h4>
          <ul>
            <li>Reuters: "Vatican Says Computer Networks Breached in Sophisticated Attack" (July 2020)</li>
            <li>Reuters: Vatican confirmation of November 2022 attack</li>
            <li>Recorded Future: Chinese state-sponsored attack documentation (2020)</li>
            <li>Cybersecurity &amp; Infrastructure Security Agency (CISA): Pattern analysis of polymorphic malware targeting nonprofits</li>
          </ul>
        </div>
      </section>

      <!-- LDS/BYU Case Study -->
      <section id="lds-byu">
        <h3>LDS/BYU: The Pattern Repeats</h3>
        <p class="text-secondary"><em>2020&ndash;2024: Four Years, Multiple Breaches</em></p>

        <h4>What Happened</h4>
        <p>Between 2020 and 2024, Latter-day Saints institutions experienced multiple documented cybersecurity incidents targeting:</p>
        <ul>
          <li>Brigham Young University student and faculty data</li>
          <li>Church educational system records</li>
          <li>Humanitarian aid distribution networks</li>
          <li>Genealogical research databases (FamilySearch)</li>
        </ul>

        <p>Each breach followed similar patterns:</p>
        <ul>
          <li>Exploitation of unpatched vulnerabilities</li>
          <li>Credential harvesting through sophisticated phishing</li>
          <li>Lateral movement within networks</li>
          <li>Extended dwell time before detection</li>
        </ul>

        <h4>Timeline</h4>
        <ol class="timeline">
          <li><span class="timeline-date">2020</span> Initial BYU network intrusion detected</li>
          <li><span class="timeline-date">2021&ndash;2022</span> Ongoing credential compromise campaigns</li>
          <li><span class="timeline-date">2023</span> FamilySearch targeted with phishing campaign</li>
          <li><span class="timeline-date">2024</span> Humanitarian logistics systems probed</li>
        </ol>

        <h4>The Impact: Expanding Circle of Harm</h4>

        <div class="card">
          <h5>For Students</h5>
          <p>Your financial aid information. Your academic records. Your private correspondence with faculty. Your medical information from Student Health Services.</p>
          <p>Compromised because the systems protecting them were designed before adversaries operated at this level of sophistication.</p>
        </div>

        <div class="card">
          <h5>For Researchers</h5>
          <p>Years of academic work. Proprietary research data. Collaborative projects with international partners.</p>
          <p>Exposed because signature-based detection cannot stop novel attack vectors.</p>
        </div>

        <div class="card">
          <h5>For Humanitarian Operations</h5>
          <p>Distribution networks for aid in crisis zones. Partner organization contacts in politically sensitive regions. Resource allocation strategies.</p>
          <p>Mapped by adversaries who could exploit or sell that intelligence.</p>
        </div>

        <div class="card">
          <h5>For Genealogical Research</h5>
          <p>Billions of family history records. DNA data. Personal information spanning generations. The collective heritage of humanity's family trees.</p>
          <p>Targeted because it represents irreplaceable value&mdash;and inadequate defenses.</p>
        </div>

        <h4>The Pattern Across Faith Traditions</h4>
        <ul>
          <li>Vatican: Breach</li>
          <li>LDS/BYU: Multiple breaches</li>
          <li>[Other denominations face similar but undisclosed incidents]</li>
        </ul>

        <p>This is not coincidence. This is systematic targeting of institutions that:</p>
        <ul>
          <li>Hold high-value data (pastoral communications, member information, financial records)</li>
          <li>Maintain trust-based relationships (confidentiality expectations)</li>
          <li>Deploy legacy security infrastructure (budget constraints, non-technical focus)</li>
          <li>Respond at human speed (manual review, quarterly audits)</li>
        </ul>

        <div class="callout">
          <h4>For Faith Leaders</h4>
          <p>Your institutions serve different theological traditions but face identical threats:</p>
          <ul>
            <li>Adversaries don't distinguish between Catholic and Protestant networks</li>
            <li>Polymorphic malware doesn't respect denominational boundaries</li>
            <li>Zero-day exploits work equally well against Orthodox and LDS infrastructure</li>
          </ul>
          <p><strong>The ecumenical imperative is no longer just theological. It's operational.</strong></p>
        </div>

        <div class="card">
          <h4>Primary Source</h4>
          <p><strong>Church Educational System Security Operations Center (CES-SOC)</strong><br>
          "Information Security Major Incident Response" (Version 2.08)<br>
          Author: John Payne, Chief Information Security Officer, BYU Church Educational System</p>
          <p><em>This official CISO documentation covers major incident response procedures and security events affecting BYU and Church Educational System networks (2020&ndash;2024).</em></p>
        </div>
      </section>

      <!-- Disney Case Study -->
      <section id="disney">
        <h3>Disney: When Consent Becomes Coercion</h3>
        <p class="text-secondary"><em>2023: The Arbitration Clause That Weaponized Entertainment</em></p>

        <h4>The Incident</h4>
        <p>A man and his wife visited a Disney restaurant. She had severe allergies. She informed the staff. She ordered carefully. She trusted the system.</p>
        <p><strong>She died.</strong></p>
        <p>Anaphylactic shock from allergen exposure the restaurant failed to prevent despite explicit warnings.</p>

        <h4>The Legal Response</h4>
        <p>The widower filed a wrongful death lawsuit.</p>
        <p>Disney's response: <strong>Forced arbitration.</strong></p>
        <p>Not because he'd signed a restaurant waiver. Not because he'd agreed to theme park terms.</p>
        <p>Because his household had once activated a <strong>Disney+ streaming trial</strong>. Years prior.</p>

        <div class="callout">
          <p>Buried in the Disney+ Terms of Service&mdash;18,000 words of dense legal text that 99% of users never read&mdash;was a clause:</p>
          <p><em>"By creating a Disney+ account, you agree to arbitrate all disputes with any Disney entity, for any reason, forever, waiving your right to sue in court."</em></p>
        </div>

        <p>Let that sink in:</p>
        <ul class="x-list">
          <li>Agree to stream movies &rarr; Forfeit right to sue for restaurant negligence</li>
          <li>Click "I Accept" on entertainment app &rarr; Waive legal recourse for wrongful death</li>
          <li>Free trial for kids' cartoons &rarr; Permanently bind entire household to corporate arbitration</li>
        </ul>

        <h4>The Impact</h4>
        <p>He lost his wife. To negligence. To a preventable tragedy.</p>
        <p>And when he sought accountability, he was told: <em>"You clicked 'Agree' on a streaming service. You have no right to a jury trial for her death."</em></p>

        <h4>The Design Pattern</h4>
        <p>Someone at Disney:</p>
        <ol>
          <li>Wrote those terms</li>
          <li>Decided they should be 18,000 words (unreadable)</li>
          <li>Buried the arbitration clause deep in the text</li>
          <li>Applied it to <em>all</em> Disney entities (not just streaming)</li>
          <li>Made it apply forever</li>
          <li>Linked it to unrelated services (streaming &ne; restaurant)</li>
          <li>Designed the database to remember and enforce this connection</li>
        </ol>

        <p><strong>Every step was intentional. Every step was optimized for corporate legal protection. Every step exploited the reality that users don't read terms of service.</strong></p>

        <div class="callout callout-stat">
          <span class="stat-number">9%</span>
          <p>of Americans actually read terms of service (Pew Research, 2019)</p>
        </div>

        <h4>What It Reveals for Technologists</h4>
        <p>Someone built:</p>
        <ul>
          <li>The account linkage database</li>
          <li>The terms enforcement system</li>
          <li>The arbitration clause lookup</li>
          <li>The legal automation infrastructure</li>
        </ul>

        <p>The technical sophistication required:</p>
        <ul>
          <li>Cross-platform identity management</li>
          <li>Multi-year data retention</li>
          <li>Automated legal claim processing</li>
          <li>Terms of service version control</li>
          <li>Enforcement trigger systems</li>
        </ul>

        <p><strong>This wasn't accidental. This was architected.</strong></p>

        <p>The questions for technologists who built it:</p>
        <ul>
          <li>Did you know what you were building?</li>
          <li>Did you understand it would be used to deny wrongful death claims?</li>
          <li>Did you object?</li>
          <li>Did you have anywhere to go if you objected?</li>
        </ul>

        <p>The Order exists for those who knew, objected, and had nowhere to go.</p>

        <h4>The Broader Pattern</h4>
        <p>Disney eventually dropped the forced arbitration attempt (after public outcry). But the infrastructure remains. The terms still exist. The database still links streaming to restaurants.</p>
        <p>The cage was built. It was deployed. It worked.</p>
        <p>Public shame forced a retreat in one case. How many others faced similar enforcement without media attention? We'll never know. <strong>That's the point.</strong></p>

        <div class="card">
          <h4>Source</h4>
          <p>BBC: "Disney drops bid to stop allergy death lawsuit over Disney+ terms" (August 2024)</p>
        </div>
      </section>

      <!-- Healthcare AI Case Study -->
      <section id="healthcare-ai">
        <h3>Healthcare AI: Automated Cruelty at Scale</h3>
        <p class="text-secondary"><em>2024&ndash;2025: When Algorithms Decide Who Suffers</em></p>

        <h4>The Scale of Automated Harm</h4>
        <p>Between 2024 and 2025, three forces converged to create a healthcare crisis:</p>
        <ol>
          <li>Insurance companies deployed AI to deny care at unprecedented rates</li>
          <li>Hospitals invested hundreds of millions in AI to replace caregivers</li>
          <li>The people who understand medicine and the people who understand code were systematically excluded from all decisions</li>
        </ol>
        <p><strong>The result: automated harm at industrial scale.</strong></p>

        <h4>The Insurance Denial Crisis</h4>
        <p>In October 2024, the U.S. Senate Permanent Subcommittee on Investigations released a report documenting what physicians had been reporting for years: AI systems were being weaponized to deny care.</p>

        <div class="card">
          <h5>The Numbers</h5>
          <ul>
            <li><strong>Humana's AI-driven denial rate for post-acute care:</strong> 16&times; higher than its overall denial rate</li>
            <li><strong>UnitedHealthcare's denial rate trajectory as AI automation increased:</strong>
              <ul>
                <li>2020: 10.9%</li>
                <li>2022: 22.7% (More than doubled in two years)</li>
              </ul>
            </li>
            <li><strong>CVS/Aetna's post-acute care denials:</strong> 3&times; higher than overall denial rate</li>
          </ul>
          <p><strong>Together, these three companies control 60% of Medicare Advantage enrollees.</strong></p>
        </div>

        <p>What "post-acute care" means in human terms:</p>
        <ul>
          <li>Rehabilitation after stroke</li>
          <li>Skilled nursing after surgery</li>
          <li>Physical therapy after injury</li>
          <li>Home health care for recovery</li>
          <li>Long-term hospital care for complex conditions</li>
        </ul>
        <p><strong>This is not elective care. This is the difference between recovery and permanent disability.</strong></p>

        <h4>The Process of Automated Denial</h4>
        <ol>
          <li>Patient needs post-acute care (rehabilitation, skilled nursing, continued treatment)</li>
          <li>Physician submits prior authorization request with medical justification</li>
          <li>AI system processes request in seconds</li>
          <li>Algorithm optimized for cost reduction, not patient outcomes</li>
          <li>Denial issued automatically</li>
          <li>No meaningful human review</li>
          <li>No explanation of medical reasoning</li>
          <li>Patient told: "Not medically necessary"</li>
          <li>Appeal process? Submit to another algorithm</li>
        </ol>

        <h4>AMA Survey Findings (December 2024)</h4>
        <p>The American Medical Association surveyed 1,000 physicians:</p>
        <ul>
          <li><strong>93%</strong> report AI-driven prior authorization delays patient care</li>
          <li><strong>82%</strong> say it leads patients to abandon treatment entirely</li>
          <li><strong>89%</strong> report it significantly increases physician burnout</li>
          <li><strong>61%</strong> fear AI is systematically increasing denials</li>
          <li><strong>75%</strong> report denials increased over last 5 years</li>
        </ul>

        <blockquote class="pull-quote">
          "We're watching patients die while algorithms decide their care isn't 'medically necessary.' The AI denies in seconds what would take a human reviewer minutes to actually consider. And when we appeal, 90% of the denials get overturned&mdash;which proves the algorithm is systematically wrong. But most patients never appeal. They just... stop treatment."
          <cite>&mdash; Physician testimony to the AMA</cite>
        </blockquote>

        <h4>The Hospital Replacement Crisis</h4>
        <p>While insurance companies deployed AI to deny care, hospitals deployed AI to replace the people who deliver it.</p>

        <p><strong>December 1, 2025: New York City</strong></p>
        <p>Nurses with the New York State Nurses Association testified before the City Council Committee on Hospitals about systematic patterns across the wealthiest hospital systems:</p>

        <div class="card">
          <h5>Mount Sinai Health System</h5>
          <ul>
            <li>November 2024: Opens $100 million AI research facility</li>
            <li>65,000 square feet, 40 principal investigators, 250 staff</li>
            <li>Deploys "Sofiya," an AI assistant in cardiac catheterization labs</li>
            <li>Zero consultation with nursing staff during development</li>
            <li>Zero input from clinical staff on implementation</li>
            <li>Nurses must manually check Sofiya's work for errors</li>
            <li>Hospital claims "200+ nursing hours saved"</li>
            <li>Nurses report: More work created, not less</li>
          </ul>
        </div>

        <blockquote class="pull-quote">
          "The wealthiest hospitals need to stop playing games with artificial intelligence and invest in care for those who need it most. Hospitals refuse to negotiate any guardrails or limits on the introduction of new technologies, and they refuse to disclose just how much they are spending on these risky and unproven initiatives."
          <cite>&mdash; Nancy Hagans, NYSNA President (30+ years experience)</cite>
        </blockquote>

        <blockquote class="pull-quote">
          "The hospital system proudly celebrates Sofiya, the latest AI assistant in Mount Sinai's cardiac catheterization lab. Nurses have to check Sofiya's work to make sure she hasn't made a mistake. When hospitals try to cut corners like this on safe patient care, mistakes are made, biases are magnified, and more work is often created down the line."
          <cite>&mdash; Denash Forbes, ICU Nurse (nearly 40 years experience)</cite>
        </blockquote>

        <h4>What the Nurses Demanded</h4>
        <ul class="check-list">
          <li>Inclusion in AI deployment decisions</li>
          <li>Adequate training before implementation</li>
          <li>Transparency about AI spending and risks</li>
          <li>Investment in human staff, not AI replacements</li>
          <li>Patient safety prioritized over executive pay</li>
          <li>Guardrails and limits on untested technology</li>
          <li>Right to negotiate terms of AI introduction</li>
        </ul>

        <h4>What the Hospitals Did</h4>
        <ul class="x-list">
          <li>Continued deployment with minimal consultation</li>
          <li>Claimed AI "supports" care teams rather than replacing them</li>
          <li>Simultaneously cut nursing positions while investing hundreds of millions in automation</li>
          <li>Refused to disclose AI spending or provide performance data</li>
          <li>Implemented systems without adequate training</li>
          <li>Expected nurses to catch AI errors without resources to do so</li>
        </ul>

        <h4>The Dual Exclusion</h4>
        <p>Two groups of people were systematically excluded from healthcare AI deployment decisions:</p>
        <ol>
          <li>The people who understand the code (technologists)</li>
          <li>The people who understand the patients (healthcare workers)</li>
        </ol>
        <p><strong>The people making the decisions? Administrators optimizing for cost.</strong></p>

        <div class="callout callout-stat">
          <span class="stat-number">$70.7B</span>
          <p>For-profit health insurance industry profits (2023)</p>
          <p>While patients abandon treatment because the appeals process is too complex.</p>
        </div>

        <h4>The Human Cost</h4>
        <p>Behind every statistic:</p>
        <ul>
          <li><strong>"16&times; higher denial rate"</strong> means: 16 stroke patients denied rehabilitation who could have recovered</li>
          <li><strong>"22.7% denial rate"</strong> means: Nearly 1 in 4 physicians' medical judgments overridden by algorithm</li>
          <li><strong>"$100 million AI investment"</strong> means: Nursing positions eliminated, bedside care replaced with algorithmic monitoring</li>
          <li><strong>"200+ nursing hours saved"</strong> means: 200+ hours of human contact replaced with an AI voice</li>
        </ul>

        <p><strong>These are not acceptable losses in the cost of "innovation."</strong></p>

        <div class="card">
          <h4>Primary Sources</h4>
          <ul>
            <li>U.S. Senate Permanent Subcommittee on Investigations: "Refusal of Recovery: How Medicare Advantage Insurers Have Denied Patients Access to Post-Acute Care" (October 17, 2024)</li>
            <li>American Medical Association: "Physicians Concerned AI Increases Prior Authorization Denials" (February 24, 2025)</li>
            <li>Newsweek: "Nurses Push Back on AI Adoption at New York Hospitals" (December 1, 2025)</li>
            <li>Mount Sinai Health System: Hamilton and Amabel James Center for Artificial Intelligence and Human Health (opened November 2024)</li>
            <li>California SB 1120 (Physicians Make Decisions Act): Effective January 1, 2025</li>
          </ul>
        </div>
      </section>

      <!-- Micron Case Study -->
      <section id="micron">
        <h3>Micron Technology: Infrastructure as Gatekeeping</h3>
        <p class="text-secondary"><em>December 3, 2025</em></p>

        <p>Micron Technology announced it will dissolve its Crucial consumer memory brand and exit the retail market entirely by February 2026. The stated reason: "to improve supply and support for our larger, strategic customers in faster-growing segments."</p>

        <h4>The Coordinated Squeeze</h4>
        <p>This isn't happening in isolation. As Micron abandons the consumer market:</p>
        <ul>
          <li>RAM prices have doubled in one month (Tom's Hardware)</li>
          <li>DDR5 RAM costs have caused motherboard sales to drop by 50% (TweakTown)</li>
          <li>Some RAM kits are three times as expensive as three months ago (Ars Technica)</li>
          <li>GPU and SSD prices are projected to follow the same trajectory (PC Gamer)</li>
        </ul>

        <p><strong>This is not supply and demand. This is orchestrated exclusion.</strong></p>

        <p>Consumer memory represented roughly 30% of Micron's revenue. It was never a priority. Now they're not just abandoning that 30%. They're ensuring what remains becomes unaffordable.</p>

        <h4>The Two-Pronged Attack</h4>
        <ol>
          <li><strong>Exit the consumer market</strong> &mdash; remove direct access to components</li>
          <li><strong>Let prices skyrocket</strong> &mdash; make remaining inventory economically impossible</li>
        </ol>

        <p>Without access to affordable memory chips, individual technologists cannot:</p>
        <ul class="x-list">
          <li>Build independent systems</li>
          <li>Upgrade existing hardware</li>
          <li>Maintain alternatives to corporate cloud infrastructure</li>
          <li>Participate in technology except as subscribers to services they don't control</li>
        </ul>

        <h4>The Real Message</h4>
        <p>"Larger, strategic customers" means AI data centers. It means corporations have tripled what they'll pay for memory because AI infrastructure generates more value than human participation ever will.</p>

        <p><strong>Individual humans aren't just secondary. You're being priced out intentionally.</strong></p>

        <h4>Why This Matters for Displaced Technologists</h4>
        <p>An ethical technologist displaced for refusing to build harmful AI systems faces:</p>
        <ul>
          <li>No consumer-grade components available (Micron exit)</li>
          <li>Remaining components priced 2-3&times; higher than three months ago</li>
          <li>Projected price increases across all computing hardware (GPUs, SSDs next)</li>
        </ul>

        <p>You cannot work independently when the materials are either withdrawn or made economically impossible to access. The expertise becomes irrelevant when participation requires wealth you don't have.</p>

        <div class="callout">
          <p><strong>The Pattern:</strong> Citizens were always secondary. Now they're being told they're unnecessary AND being priced out of the infrastructure entirely.</p>
          <p>The door isn't just closing. It's being bolted shut while you watch.</p>
          <p>RAM prices doubling the same week Micron exits? That's not coincidence. That's coordination.</p>
        </div>
      </section>

      <!-- The Great Hardware Liquidation Case Study -->
      <section id="hardware-liquidation">
        <h3>The Great Hardware Liquidation</h3>
        <p class="text-secondary"><em>2025: The Physical Construction of the Cage</em></p>

        <div class="callout">
          <p><strong>Visible Summary:</strong> Access to the tools of intelligence is no longer diffusing; it is being deliberately dammed. What appears as a market shortage is, in truth, the physical architecture of the "Cage"&mdash;a world where meaningful computation is structurally inaccessible to those outside institutional alignment.</p>
        </div>

        <p>By late 2025, access to advanced compute hardware is no longer diffusing into the consumer market. Instead, it is being deliberately constrained and redirected toward enterprise and AI-centric buyers. What presents publicly as supply-chain strain is, in practice, the physical construction of the Cage: a system in which meaningful computation is structurally inaccessible without institutional alignment.</p>

        <h4>The Evidence: Market Abandonment</h4>
        <p>Between late 2024 and early 2025, the industry witnessed a decisive withdrawal from enthusiast markets. Product lines like the Solidigm P44 Pro and Crucial MX500 were not just discontinued; they were abandoned as "economically non-strategic."</p>

        <div class="card">
          <h5>Supplementary Evidence: Controlled Contraction</h5>
          <p>Beginning in late 2025, multiple reports confirmed that <strong>NVIDIA intends to reduce consumer GPU production by up to 40% in early 2026</strong>.</p>
          <p>While memory shortages are cited, the redirection of these same resources to data center accelerators proves that supply is not collapsing&mdash;<strong>it is being re-allocated</strong>.</p>
          <p>The RTX 50-series production cut is the most powerful evidence that the "lockout" is an active choice, not an accident.</p>
        </div>

        <h4>The Cultural Impact: Normalization</h4>
        <p>Developer communities are being conditioned to accept scarcity as "inevitable." This is a loss of agency. When we accept longer upgrade cycles and reduced performance targets, we are accepting the loss of our primary substrate for experimentation and independent innovation.</p>

        <p><strong>This normalization is itself a form of capture.</strong></p>

        <h4>The Structural Analysis: The Compute Divide</h4>
        <p>The crisis operates across three interconnected layers:</p>

        <div class="card">
          <h5>PHYSICAL SCARCITY (THE HARDWARE LOCKOUT)</h5>
          <p>Advanced VRAM and HBM are reserved for the institutional elite. Independent capability is sacrificed at the altar of enterprise priority.</p>
          <ul>
            <li>Consumer GPUs receive reduced memory allocations</li>
            <li>Production capacity deliberately constrained for retail</li>
            <li>First-right-of-refusal granted to datacenter buyers</li>
          </ul>
        </div>

        <div class="card">
          <h5>FINANCIAL ASYMMETRY (THE DEPRECIATION MOAT)</h5>
          <p>Corporations do not "buy" hardware; they "amortize" it. The individual developer pays a "retail tax" that the conglomerate bypasses through structural accounting.</p>
          <ul>
            <li>Identical hardware occupies different economic realities</li>
            <li>Corporate depreciation vs. personal expenditure</li>
            <li>Tax treatment advantages institutional buyers</li>
          </ul>
        </div>

        <div class="card">
          <h5>INTELLECTUAL CAPTURE (THE RENTAL ECONOMY)</h5>
          <p>When you cannot own the substrate, you must rent the soul. Innovation becomes a "permission-based" activity.</p>
          <ul>
            <li>Cloud APIs replace local compute ownership</li>
            <li>Terms of service govern what you can create</li>
            <li>Independent research requires institutional approval</li>
          </ul>
        </div>

        <h4>The Intervention: The Order's Shield</h4>
        <p>The Shield does not dismantle the Cage; it preserves autonomy within it through:</p>

        <ul class="check-list">
          <li><strong>Infrastructure Pooling:</strong> Collective ownership to bypass individual scarcity</li>
          <li><strong>Decentralized Compute:</strong> Using networks like Neurolov and Bittensor to build un-censorable intelligence</li>
          <li><strong>Sanctuary Framing:</strong> Grounding our work in shared values rather than extraction</li>
        </ul>

        <blockquote class="pull-quote">
          The Great Hardware Liquidation is the quiet redefinition of who computation is for. The answer is already written in the market signals.
        </blockquote>

        <div class="card">
          <h4>References</h4>
          <ul>
            <li>PCMag. "Nvidia Might Cut RTX 50 GPU Supply by Up to 40% in 2026" (2025)</li>
            <li>Windows Central. "NVIDIA could cut RTX GPU production by up to 40% in 2026" (2025)</li>
            <li>OC3D. "Nvidia plans heavy cuts to GPU supply in early 2026" (2025)</li>
            <li>PC Gamer. "Nvidia might be seriously cutting GeForce GPU supply because of VRAM shortage" (2025)</li>
            <li>TechPowerUp. "NVIDIA Plans to Reduce RTX 50 Production by Up to 40% in Early 2026" (2025)</li>
          </ul>
        </div>
      </section>

      <!-- The Erasure of the Fallback Case Study -->
      <section id="erasure-fallback">
        <h3>Case Study II: The Erasure of the Fallback</h3>
        <p class="text-secondary"><em>December 18, 2025 &mdash; Status: Operational Intelligence / The Order</em></p>
        <p><strong>Focus: Supply-Side Strangling and the Stasis Trap</strong></p>

        <h4>I. Executive Summary</h4>
        <p>Technological progress has historically preserved a "fallback option." When new systems became prohibitively expensive or institutionally gated, independent operators could retreat to reliable legacy hardware to continue autonomous innovation. In 2025, that retreat is being systematically eliminated.</p>

        <p>Through supply-side strangulation, the industry is liquidating the past to enforce a <strong>Stasis Trap</strong>: a condition in which forward movement requires institutional alignment, while backward movement is impossible because the physical substrate of prior generations no longer exists.</p>

        <h4>II. The Severing of the Past</h4>
        <p><strong>Mechanism: Strategic Discontinuation</strong></p>
        <p>The primary tool of the "Lockout" is the deliberate removal of consumer-facing foundational components. Manufacturers have transitioned from "powering the individual" to "serving the cluster."</p>

        <div class="card">
          <h5>Evidence of Strategic Discontinuation</h5>
          <ul>
            <li><strong>SSD Liquidation:</strong> As of early 2025, manufacturers like Solidigm and Crucial have officially exited the consumer SSD market, discontinuing veteran lines like the P44 Pro and MX500.</li>
            <li><strong>Data Center Pivot:</strong> Internal roadmaps now prioritize "Enterprise Storage" and "High-Density Clusters," abandoning the very drives that allowed independent developers to maintain affordable local servers.</li>
            <li><strong>The Loss of Choice:</strong> By removing "old reliable" SATA and mainstream NVMe options from production, the industry forces a migration toward high-cost, institutional-grade storage.</li>
          </ul>
        </div>

        <div class="callout">
          <p><strong>The Stasis Trap:</strong> You cannot move forward without institutional approval. You cannot move backward because the fallback hardware no longer exists. The only option remaining is compliance or obsolescence.</p>
        </div>

        <h4>The Pattern Emerges</h4>
        <p>This is not market evolution. This is coordinated elimination:</p>
        <ul>
          <li>Consumer SSDs discontinued &rarr; No affordable local storage</li>
          <li>Consumer RAM brands dissolved &rarr; No affordable memory upgrades</li>
          <li>Consumer GPU production cut &rarr; No affordable compute access</li>
          <li>Legacy product lines terminated &rarr; No fallback position</li>
        </ul>

        <p><strong>The cage isn't just being built. The escape routes are being demolished.</strong></p>
      </section>

      <!-- Part II: Displaced Technologists -->
      <section>
        <h2>Part II: Displaced Ethical Technologists</h2>
        <p class="text-secondary"><em>The People Who Refused to Build the Cage</em></p>
      </section>

      <!-- Google Case Study -->
      <section id="google">
        <h3>Google: The Ethics Team That Wasn't</h3>
        <p class="text-secondary"><em>2020&ndash;2021: When "Don't Be Evil" Became Obsolete</em></p>

        <h4>What Happened</h4>

        <p><strong>November 2020:</strong> Dr. Timnit Gebru, co-lead of Google's Ethical AI team, submitted a research paper examining bias in large language models. The paper raised concerns about:</p>
        <ul>
          <li>Environmental costs of training massive models</li>
          <li>Bias embedded in training data</li>
          <li>Risks of deploying systems without adequate testing</li>
          <li>Corporate incentives misaligned with ethical deployment</li>
        </ul>

        <p>Google's response: Demanded that the paper be retracted or the authors' names removed.</p>
        <p>Dr. Gebru's response: Raised concerns about censorship of ethical research.</p>
        <p>Google's action: <strong>Terminated her employment.</strong></p>
        <ul>
          <li>Official reason: "Resigned"</li>
          <li>Real reason: Raised inconvenient truths about products Google planned to deploy</li>
        </ul>

        <p><strong>February 2021:</strong> Dr. Margaret Mitchell, the other co-lead of Google's Ethical AI team, continued Dr. Gebru's work and advocated internally for accountability.</p>
        <p>Google's action: <strong>Terminated her employment.</strong></p>
        <ul>
          <li>Official reason: "Violated security policies"</li>
          <li>Real reason: Wouldn't stop asking questions about AI ethics and bias</li>
        </ul>

        <p><strong>2021&ndash;2022:</strong> Google's Ethical AI team systematically dismantled:</p>
        <ul>
          <li>Researchers reassigned</li>
          <li>Projects defunded</li>
          <li>Team members departing</li>
          <li>Ethical review processes weakened</li>
        </ul>

        <p><strong>The result:</strong> Google deployed AI products at scale with minimal ethical oversight.</p>

        <h4>For Those Who Stayed</h4>
        <p>Imagine coming to work after your team leads were terminated for doing their jobs.</p>
        <p>Imagine being told "ethical review" but knowing dissent means unemployment.</p>
        <p>Imagine having the expertise to identify problems but no protection to raise them.</p>
        <p><strong>That's not a job. That's complicity under duress.</strong></p>

        <h4>What It Reveals</h4>

        <p>This case reveals the corporate ethics paradox:</p>
        <ol>
          <li>Companies create ethics teams (good PR, regulatory appeasement)</li>
          <li>Ethics teams discover actual ethical problems (doing their job)</li>
          <li>Problems conflict with product timelines or revenue (predictable)</li>
          <li>Companies choose profits (consistent with fiduciary duty to shareholders)</li>
          <li>Ethics teams object (doing their job)</li>
          <li>Companies terminate ethics teams (removing the inconvenience)</li>
        </ol>

        <p><strong>The cycle:</strong> Hire ethicists &rarr; Ethicists find problems &rarr; Problems cost money &rarr; Fire ethicists &rarr; Claim you "take ethics seriously" &rarr; Repeat</p>

        <p>The Google case is not unique. <strong>It's the template.</strong></p>

        <div class="callout">
          <h4>For Faith Leaders</h4>
          <p>Ask yourself: Why does Google&mdash;one of the world's wealthiest, most technically sophisticated companies&mdash;fire the people tasked with ensuring its AI is ethical?</p>
          <p>Not because ethics don't matter.</p>
          <p><strong>Because ethics that cost money don't matter in a system optimized for shareholder value.</strong></p>
          <p>The structural problem:</p>
          <ul>
            <li>Public corporations have fiduciary duty to maximize shareholder returns</li>
            <li>Ethical constraints often reduce short-term profits</li>
            <li>Therefore, ethics teams become liability when they actually function</li>
          </ul>
          <p>This is not a bug in corporate governance. This is the system working as designed.</p>
        </div>

        <h4>The Order's Proposal</h4>
        <p>Employ technologists within faith-based institutions where:</p>
        <ul class="check-list">
          <li>Fiduciary duty is to mission, not shareholders</li>
          <li>Long-term human flourishing outweighs quarterly earnings</li>
          <li>Ethical constraints are features, not bugs</li>
          <li>Institutional backing protects principled objection</li>
        </ul>

        <p>What Google did to Dr. Gebru and Dr. Mitchell, <strong>faith institutions can refuse to do.</strong></p>

        <h4>The Broader Implications</h4>
        <p>If Google&mdash;with its "Don't Be Evil" origins&mdash;terminates ethics researchers for doing ethics research...</p>
        <p>If the most visible, well-resourced AI ethics team in industry can be dismantled for inconvenient findings...</p>
        <p><strong>What hope do less prominent technologists have when they raise concerns?</strong></p>
        <p>Answer: None. Without institutional sanctuary.</p>
        <p><strong>That's why the Order exists.</strong></p>

        <div class="card">
          <h4>Sources</h4>
          <ul>
            <li>MIT Technology Review: Coverage of Gebru and Mitchell terminations (2020&ndash;2021)</li>
            <li>NPR: "Google Fires Researcher Timnit Gebru" (December 2020)</li>
            <li>The New York Times: Coverage of Google Ethical AI team dissolution</li>
            <li>TIME Magazine: Analysis of corporate ethics team patterns</li>
          </ul>
        </div>
      </section>

      <!-- The Choice Section -->
      <section>
        <h2>The Choice Before Us</h2>

        <div class="two-paths">
          <article class="path-card path-sponsor">
            <h3>For Faith Leaders</h3>
            <p>You can deploy the same AI systems secular hospitals deploy. Optimize for cost like everyone else. Tell yourself your mission statement makes you different.</p>
            <p><strong>Or you can:</strong> Build AI that actually aligns with your values. Prove your mission governs your technology.</p>
            <a href="faith-leaders/problem.html" class="btn btn-sponsor">Learn More &rarr;</a>
          </article>

          <article class="path-card path-recruit">
            <h3>For Technologists</h3>
            <p>You can build systems that deny care to maximize profit. Tell yourself "I'm just building what I'm told."</p>
            <p><strong>Or you can:</strong> Refuse to build systems optimized against patient outcomes. Join institutions that will protect you when you say no.</p>
            <a href="technologists/call.html" class="btn btn-recruit">Learn More &rarr;</a>
          </article>
        </div>

        <blockquote class="pull-quote">
          "These case studies document what is happening right now. The question is not whether harmful AI will be deployed. It's already being deployed. The question is: Who will build the alternative?"
        </blockquote>
      </section>

    </div>
  </main>

  <footer class="site-footer">
    <p class="footer-tagline">"Building the Shield, Refusing the Cage"</p>
    <nav class="footer-nav" aria-label="Footer navigation">
      <a href="index.html">Home</a>
      <a href="faith-leaders/problem.html">For Faith Leaders</a>
      <a href="technologists/call.html">For Technologists</a>
      <a href="case-studies.html">Case Studies</a>
      <a href="about/rome-call.html">Rome Call</a>
      <a href="faq.html">FAQ</a>
      <a href="sources.html">Sources</a>
      <a href="contact.html">Contact</a>
    </nav>
    <nav class="footer-legal" aria-label="Legal links">
      <a href="privacy.html">Privacy Policy</a>
      <a href="terms.html">Terms of Service</a>
      <a href="accessibility.html">Accessibility</a>
      <a href="transparency.html">Transparency Report</a>
      <a href="cookie-notice.html">Cookie Notice</a>
    </nav>
    <p class="footer-copy">&copy; 2025 The Order of Ethical Technologists. All rights reserved.</p>
  </footer>

  <script src="js/theme.js"></script>
</body>
</html>
