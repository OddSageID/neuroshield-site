---
lang: it
ref: about-rome-call
---
<!DOCTYPE html>
<html lang="{{ page.lang | default: 'en' }}" dir="{% if page.lang == 'ar' %}rtl{% else %}ltr{% endif %}">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Rome Call for AI Ethics - iniziativa globale del Vaticano che stabilisce principi etici per l'intelligenza artificiale.">
  <title>Informazioni sul Rome Call - The Order of Ethical Technologists</title>
  <!-- Security -->
  <meta http-equiv="Content-Security-Policy" content="default-src 'none'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; font-src 'self'; connect-src 'self'; frame-ancestors 'none'; base-uri 'self'; form-action 'self'; upgrade-insecure-requests;">
  <meta http-equiv="X-Content-Type-Options" content="nosniff">
  <meta http-equiv="X-Frame-Options" content="DENY">
  <meta name="referrer" content="strict-origin-when-cross-origin">
  <meta http-equiv="Permissions-Policy" content="accelerometer=(), camera=(), geolocation=(), gyroscope=(), magnetometer=(), microphone=(), payment=(), usb=(), interest-cohort=()">

  <link rel="stylesheet" href="{{ '/css/fonts.css' | relative_url }}">
  <link rel="stylesheet" href="{{ '/css/style.css' | relative_url }}">
  {% include hreflang.html %}
</head>
<body class="theme-home">

  <a href="#main-content" class="skip-link">Vai al contenuto principale</a>

  {% include nav.html %}

  <header class="hero hero-shared">
    <div class="container container-wide">
      <p class="breadcrumb">Informazioni</p>
      <h1>Il fondamento: Rome Call for AI Ethics</h1>
    </div>
  </header>

  <main id="main-content">
    <div class="container">

      <section class="section">
        <h2>Che cos'è il Rome Call?</h2>
        <p>Nel 2020, il Vaticano ha lanciato il "Rome Call for AI Ethics"&mdash;un'iniziativa globale per stabilire principi etici per lo sviluppo e l'impiego dell'intelligenza artificiale.</p>

        <h3>I firmatari includono:</h3>
        <ul>
          <li>La Santa Sede (Vaticano)</li>
          <li>Microsoft</li>
          <li>IBM</li>
          <li>Food and Agriculture Organization (FAO)</li>
          <li>Governo italiano</li>
          <li>Molte istituzioni di fede e ONG</li>
        </ul>

        <p><strong>L'obiettivo:</strong> creare un quadro etico condiviso che trascenda confini religiosi, politici e aziendali.</p>
      </section>

      <section class="section">
        <h2>I sei principi</h2>

        <div class="card">
          <h3>1. Trasparenza</h3>
          <p>I sistemi di IA devono essere spiegabili e comprensibili. Gli algoritmi a scatola nera che prendono decisioni senza comprensione umana sono inaccettabili.</p>
          <p><strong>Traduzione tecnica:</strong> l'IA spiegabile (XAI) deve essere standard. Ogni decisione automatizzata deve essere verificabile.</p>
        </div>

        <div class="card">
          <h3>2. Inclusione</h3>
          <p>L'IA deve servire tutte le persone, soprattutto i vulnerabili e gli emarginati. La tecnologia non può essere progettata solo per i privilegiati.</p>
          <p><strong>Traduzione tecnica:</strong> il rilevamento e la correzione dei bias devono essere integrati nel design. L'accessibilità è obbligatoria, non opzionale.</p>
        </div>

        <div class="card">
          <h3>3. Responsabilità</h3>
          <p>Chi progetta, implementa e trae profitto dall'IA deve essere responsabile dei suoi effetti. L'automazione non elimina la responsabilità.</p>
          <p><strong>Traduzione tecnica:</strong> è necessaria una supervisione human-in-the-loop. Nessuna decisione completamente autonoma in contesti ad alto rischio.</p>
        </div>

        <div class="card">
          <h3>4. Imparzialità</h3>
          <p>L'IA non deve creare o rafforzare bias e discriminazioni. L'equità deve essere quantificata e verificata.</p>
          <p><strong>Traduzione tecnica:</strong> audit regolari sui bias demografici, test continui, report pubblici di trasparenza.</p>
        </div>

        <div class="card">
          <h3>5. Affidabilità</h3>
          <p>I sistemi di IA devono funzionare in modo sicuro e affidabile. I sistemi inaffidabili non possono essere implementati su larga scala.</p>
          <p><strong>Traduzione tecnica:</strong> protocolli di test rigorosi, meccanismi di fail-safe, monitoraggio continuo, segnalazione degli incidenti.</p>
        </div>

        <div class="card">
          <h3>6. Sicurezza e privacy</h3>
          <p>L'IA deve proteggere i dati degli utenti e resistere ad attacchi malevoli. La privacy è un diritto, non una merce.</p>
          <p><strong>Traduzione tecnica:</strong> architettura privacy-by-design, standard di cifratura, raccolta dati minima, controllo dell'utente.</p>
        </div>
      </section>

      <section class="section">
        <h2>Perché è importante</h2>
        <p>Il Rome Call ha ottenuto qualcosa di senza precedenti: <strong>consenso globale tra interessi in competizione.</strong></p>
        <ul>
          <li>Le aziende hanno accettato vincoli etici</li>
          <li>I governi hanno assunto impegni di allineamento delle politiche</li>
          <li>Le tradizioni di fede hanno trovato un terreno comune</li>
          <li>Le ONG hanno convalidato l'approccio complessivo</li>
        </ul>
        <p><strong>Il risultato:</strong> tutti concordano sui principi.</p>
        <p><strong>Il problema:</strong> nessuno ha costruito l'infrastruttura per implementarli.</p>
      </section>

      <section class="section">
        <h2>La conferenza vaticana di novembre 2025</h2>
        <p><strong>"Artificial Intelligence and Medicine: Ethics and Governance"</strong></p>

        <h3>Partecipanti:</h3>
        <ul>
          <li>Leadership della Chiesa cattolica</li>
          <li>Rappresentanti LDS/Mormoni</li>
          <li>Istituzioni cristiane ortodosse</li>
          <li>Denominazioni protestanti</li>
          <li>Professionisti medici</li>
          <li>Ricercatori di IA</li>
          <li>Esperti di politiche</li>
        </ul>

        <h3>Esiti:</h3>
        <ol>
          <li>Riaffermato l'impegno verso i principi del Rome Call</li>
          <li>Identificate preoccupazioni specifiche nell'IA sanitaria</li>
          <li>Dimostrato che la collaborazione ecumenica esiste già</li>
          <li>Riconosciuta la necessità di infrastrutture operative</li>
        </ol>

        <p><strong>Cosa mancava:</strong> un meccanismo per trasformare il dialogo in implementazione.</p>
        <p><strong>Questo è ciò che offre l'Ordine.</strong></p>
      </section>

      <section class="section">
        <h2>Dai principi alla pratica</h2>
        <div class="diagram">
          <div class="diagram-flow">
            <div class="diagram-box">Principi del Rome Call</div>
            <span class="diagram-arrow">&darr;</span>
            <div class="diagram-box">Conferenza Vaticana 2025<br><small>(Dialogo e impegno)</small></div>
            <span class="diagram-arrow">&darr;</span>
            <div class="diagram-box">L'Ordine dei Tecnologi Etici<br><small>(Infrastruttura operativa)</small></div>
            <span class="diagram-arrow">&darr;</span>
            <div class="diagram-box">Sistemi implementati<br><small>(Protezione e responsabilità reali)</small></div>
          </div>
        </div>
      </section>

      <section class="section">
        <div class="pull-quote">
          "Il Rome Call non è solo cattolico. Non è solo cristiano. È un quadro umano per l'IA che serve la dignità umana."
          <cite>L'Ordine lo rende reale.</cite>
        </div>
      </section>

      <section class="btn-group section">
        <a href="{{ '/faith-leaders/problem.html' | relative_url }}" class="btn btn-sponsor">Per i leader di fede</a>
        <a href="{{ '/technologists/call.html' | relative_url }}" class="btn btn-recruit">Per i tecnologi</a>
      </section>

    </div>
  </main>

  <footer class="site-footer">
    <p class="footer-tagline">"Costruire lo scudo, rifiutare la gabbia"</p>
    <nav class="footer-nav" aria-label="Navigazione del footer">
      <a href="{{ '/' | relative_url }}">Home</a>
      <a href="{{ '/faith-leaders/problem.html' | relative_url }}">Per i leader di fede</a>
      <a href="{{ '/technologists/call.html' | relative_url }}">Per i tecnologi</a>
      <a href="{{ '/case-studies.html' | relative_url }}">Casi di studio</a>
      <a href="{{ '/about/rome-call.html' | relative_url }}">Rome Call</a>
      <a href="{{ '/about/displacement-pattern.html' | relative_url }}">Guida sul campo</a>
      <a href="{{ '/faq.html' | relative_url }}">FAQ</a>
      <a href="{{ '/sources.html' | relative_url }}">Fonti</a>
      <a href="{{ '/contact.html' | relative_url }}">Contatti</a>
    </nav>
    <nav class="footer-legal" aria-label="Link legali">
      <a href="{{ '/privacy.html' | relative_url }}">Informativa sulla privacy</a>
      <a href="{{ '/terms.html' | relative_url }}">Termini di servizio</a>
      <a href="{{ '/accessibility.html' | relative_url }}">Accessibilità</a>
      <a href="{{ '/transparency.html' | relative_url }}">Rapporto di trasparenza</a>
      <a href="{{ '/cookie-notice.html' | relative_url }}">Informativa sui cookie</a>
    </nav>
    <p class="footer-copy">&copy; 2025 The Order of Ethical Technologists. Tutti i diritti riservati.</p>
  </footer></body>
</html>
